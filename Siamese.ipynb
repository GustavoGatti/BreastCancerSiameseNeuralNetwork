{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Ut_-9GxRpKPRGw_eUIeY_tDHzJ73-Fo",
      "authorship_tag": "ABX9TyPCHrxl+G9SOOg2R6lbaYXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoGatti/BreastCancerSiameseNeuralNetwork/blob/main/Siamese.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUOu3XKMKSq4"
      },
      "source": [
        "Teste da implementação da redes neurais siameses convolucional\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sZUL6t-FHu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "2deb6591-4256-494d-bd9e-4c151976d048"
      },
      "source": [
        "!pip install tensorflow-gpu==2.2.0-rc0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.2.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.2.0rc0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (2.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (2.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.18.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (2.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.12.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (0.34.2)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.2.0-rc0) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu==2.2.0-rc0) (49.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (3.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu==2.2.0-rc0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEOdcMUMZNZA"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Input, Lambda, Reshape\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import ndarray\n",
        "import numpy.random as rng\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwT0W49nPDd6"
      },
      "source": [
        "from keras import backend as K\n",
        "import keras as KER"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf0ojl08QhsW"
      },
      "source": [
        "from keras.layers import merge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYgav8IZOTl"
      },
      "source": [
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBDUEF6qeOy9"
      },
      "source": [
        "def cosine(vector):\n",
        "  x, y = vector\n",
        "  dotx = K.sum(x*x, axis=1,keepdims=True)\n",
        "  doty = K.sum(y*y, axis=1,keepdims=True)\n",
        "  dotxy = K.sum(x*y, axis=1,keepdims=True)\n",
        "  cos = (dotxy/(K.sqrt(dotx) * K.sqrt(doty)))\n",
        "  return cos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnETei8lh15y"
      },
      "source": [
        "def eucl_dist_output_shape(shapes):\n",
        "  shape1, shape2 = shapes\n",
        "  return shape1[0], 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYVKaqmaiG_U"
      },
      "source": [
        "def contrastive_loss(y_true,y_pred):\n",
        "  return K.mean(y_true*(2*K.exp(-(1/K.square(y_pred-1.2)))) + (1 - y_true)*(2*K.exp(-(1/K.square(y_pred+1.2)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmnKvvKNjq6F"
      },
      "source": [
        "def logistic_loss(y_true,y_pred):\n",
        "  return K.mean(K.log(1 * K.exp(-1*y_pred*y_true)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSmw5XZBNW78"
      },
      "source": [
        "def compute_accuracy(y_true,y_pred):\n",
        "  classified = K.round(y_pred)\n",
        "  return K.mean(K.equal(classified, y_true))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV22GDbiOyC8"
      },
      "source": [
        "def compute_final_accuracy(predictions, labels, print_prediction = False):\n",
        "  if print_prediction:\n",
        "    print(predictions)\n",
        "\n",
        "  classified = np.round(predictions.ravel())\n",
        "  return np.mean(classified == labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9bLFdbsgKPw"
      },
      "source": [
        "def difference(vector):\n",
        "  x, y = vector\n",
        "  return x-y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R_d8FvmgWe5"
      },
      "source": [
        "def cos_distance(vector):\n",
        "  return 1-cosine(vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSzU8taogkCh"
      },
      "source": [
        "def distance(cos):\n",
        "  return 1 - K.abs(cos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qKfad5JM8HE"
      },
      "source": [
        "initialize_weights = KER.initializers.RandomNormal(mean=0.0, stddev=0.51, seed=50001)\n",
        "initialize_bias = KER.initializers.RandomNormal(mean=0.0, stddev=0.1, seed=1221)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K61aazNvZZvt"
      },
      "source": [
        "def criando_rede(input_shape):\n",
        "\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=32, kernel_size=2, activation = 'relu', input_shape = input_shape, kernel_initializer=initialize_weights, kernel_regularizer=l2(2e-4)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Conv1D(filters=64, kernel_size=2, activation = 'relu',kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation = 'relu',kernel_initializer=initialize_weights,\n",
        "                     bias_initializer=initialize_bias, kernel_regularizer=l2(2e-4)))\n",
        "\n",
        "  model.add(Dense(1, activation = 'sigmoid', kernel_regularizer=l2(1e-3),\n",
        "                   kernel_initializer=initialize_weights,bias_initializer=initialize_bias))\n",
        "  '''\n",
        "  model = Sequential()\n",
        "  model.add(keras.layers.Reshape(input_shape = (9, 1), target_shape=(9,1)))\n",
        "  model.add(Conv1D(filters=32, kernel_size=2, activation = 'relu', input_shape = (9,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Conv1D(filters=64, kernel_size=2, activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Dense(64, activation = 'relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  '''\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xknoYT0Sa2RZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0ddaae8e-7776-4219-8e83-4336d94040b3"
      },
      "source": [
        "'''\n",
        "def execute(epochs=50):\n",
        "  np.random.seed(100)\n",
        "  random.seed(100)\n",
        "\n",
        "  #creat dataset\n",
        "\n",
        "  input_dim = (9,1)\n",
        "\n",
        "  rede_base = criando_rede(input_dim)\n",
        "  input_left = Input(input_dim)\n",
        "  input_right = Input(input_dim)\n",
        "\n",
        "  left_side = rede_base(input_left)\n",
        "  right_side = rede_base(input_right)\n",
        "\n",
        "  both = merge([left_side, right_side], mode=cosine, output_shape=eucl_dist_output_shape)\n",
        "\n",
        "  model = Model(input=[input_left, input_right], output=both)\n",
        "\n",
        "  loss = contrastive_loss\n",
        "  optimizer = Adam(0.00005)\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,metrics=[\"acurracy\"])\n",
        "  hist = model.fit(train_x, train_y, epochs=50, validation_data=(test_x, test_y))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef execute(epochs=50):\\n  np.random.seed(100)\\n  random.seed(100)\\n\\n  #creat dataset\\n\\n  input_dim = (9,1)\\n\\n  rede_base = criando_rede(input_dim)\\n  input_left = Input(input_dim)\\n  input_right = Input(input_dim)\\n\\n  left_side = rede_base(input_left)\\n  right_side = rede_base(input_right)\\n\\n  both = merge([left_side, right_side], mode=cosine, output_shape=eucl_dist_output_shape)\\n\\n  model = Model(input=[input_left, input_right], output=both)\\n\\n  loss = contrastive_loss\\n  optimizer = Adam(0.00005)\\n  model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,metrics=[\"acurracy\"])\\n  hist = model.fit(train_x, train_y, epochs=50, validation_data=(test_x, test_y))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHaPEDz5AbdP"
      },
      "source": [
        "def Transformacao(dataset):\n",
        "\n",
        "  novo_data = pd.DataFrame(data=dataset)\n",
        "  novo_data.drop('Classification',inplace=True,axis=1)  \n",
        "  data_x = novo_data \n",
        "  data_y = dataset.Classification\n",
        "  x_train = np.asarray(data_x)\n",
        "  y_train = np.asarray(data_y)\n",
        "  print(x_train)\n",
        "  test_x = []\n",
        "  test_y = []\n",
        "  for i in range(116):\n",
        "    if(i<7):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "    elif(i>99):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "\n",
        "\n",
        "  test_x = np.asarray(test_x)\n",
        "  test_y = np.asarray(test_y)\n",
        "  print(test_x.shape)\n",
        "  print(test_y.shape)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  test_x = scaler.fit_transform(test_x)\n",
        "  x_train = scaler.fit_transform(x_train)\n",
        "  x_train = x_train.reshape(116,9,1)\n",
        "  test_x = test_x.reshape(23,9,1)\n",
        "\n",
        "  return test_x, test_x, test_y, test_y, scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gto0BaUiBRGh"
      },
      "source": [
        "def Montando_data_set(x_train,x_train1,y_train,y_train1):\n",
        "  target = []\n",
        "  trainx = []\n",
        "  trainx1 =[]\n",
        "  print(y_train)\n",
        "  print(y_train1)\n",
        "  print(len(x_train))\n",
        "  print(len(x_train1))\n",
        "  for i in range(23):\n",
        "    for j in range(23):\n",
        "      trainx.append(x_train[i])\n",
        "      trainx1.append(x_train1[j])\n",
        "      if(y_train[i] == y_train1[j]):\n",
        "        target.append(1)\n",
        "      else:\n",
        "        target.append(0)\n",
        "  trainx=np.asarray(trainx)\n",
        "  trainx1=np.asarray(trainx1)\n",
        "  xtreino = [trainx,trainx1]\n",
        "  target = np.asarray(target)\n",
        "\n",
        "  return xtreino,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeY0XZVPAcNW"
      },
      "source": [
        "def Transformacao_teste(dataset):\n",
        "\n",
        "  novo_data = pd.DataFrame(data=dataset)\n",
        "  novo_data.drop('Classification',inplace=True,axis=1)  \n",
        "  data_x = novo_data \n",
        "  data_y = dataset.Classification\n",
        "  x_train = np.asarray(data_x)\n",
        "  y_train = np.asarray(data_y)\n",
        "  print(x_train)\n",
        "  test_x = []\n",
        "  test_y = []\n",
        "  y = 0\n",
        "  for i in range(116):\n",
        "    if((i>7) & (i<15)):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "      y = y+1\n",
        "    elif((i>85) & (i<95) ):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "      y = y+1\n",
        "\n",
        "  print(y)\n",
        "  test_x = np.asarray(test_x)\n",
        "  test_y = np.asarray(test_y)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  test_x = scaler.fit_transform(test_x)\n",
        "  print(test_x.shape)\n",
        "  test_x = test_x.reshape(16,9,1)\n",
        "\n",
        "  return test_x, test_x, test_y, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RklgjIOv2yX6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "12871b4d-2bef-47fe-d7c4-6b5421a8ea9d"
      },
      "source": [
        "'''\n",
        "cancer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataR234.csv')\n",
        "x_train1, x_train2, y_train1, y_train2 = _Dataset(cancer)\n",
        "x_train, y_train = Montando_data_set(x_train1,x_train2, y_train1, y_train2)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ncancer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataR234.csv')\\nx_train1, x_train2, y_train1, y_train2 = _Dataset(cancer)\\nx_train, y_train = Montando_data_set(x_train1,x_train2, y_train1, y_train2)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enM3BSEIPEC6"
      },
      "source": [
        "def Montando_data_set_test(x_train,x_train1,y_train,y_train1):\n",
        "  target = []\n",
        "  trainx = []\n",
        "  trainx1 =[]\n",
        "  print(y_train)\n",
        "  print(y_train1)\n",
        "  print(len(x_train))\n",
        "  print(len(x_train1))\n",
        "  for i in range(16):\n",
        "    for j in range(16):\n",
        "      trainx.append(x_train[i])\n",
        "      trainx1.append(x_train1[j])\n",
        "      if(y_train[i] == y_train1[j]):\n",
        "        target.append(1)\n",
        "      else:\n",
        "        target.append(0)\n",
        "  trainx=np.asarray(trainx)\n",
        "  trainx1=np.asarray(trainx1)\n",
        "  xtreino = [trainx,trainx1]\n",
        "  target = np.asarray(target)\n",
        "\n",
        "  return xtreino,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XVOJ_moAuIY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "a8358017-c213-4245-cf5c-a56b37ec4aec"
      },
      "source": [
        "cancer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataR234.csv')\n",
        "x, x1, y, y1, scaler = Transformacao(cancer)\n",
        "x_train, y_train = Montando_data_set(x,x1,y,y1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 48.          23.5         70.         ...   9.7024       7.99585\n",
            "  417.114     ]\n",
            " [ 83.          20.69049454  92.         ...   5.429285     4.06405\n",
            "  468.786     ]\n",
            " [ 82.          23.12467037  91.         ...  22.43204      9.27715\n",
            "  554.697     ]\n",
            " ...\n",
            " [ 65.          32.05        97.         ...  22.54        10.33\n",
            "  314.05      ]\n",
            " [ 72.          25.59        82.         ...  33.75         3.27\n",
            "  392.46      ]\n",
            " [ 86.          27.18       138.         ...  14.11         4.35\n",
            "   90.09      ]]\n",
            "(23, 9)\n",
            "(23,)\n",
            "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "[0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "23\n",
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z7jjm-hQnZV"
      },
      "source": [
        "cancer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataR234.csv')\n",
        "x12, x123, y12, y123 = Transformacao_teste(cancer)\n",
        "x_test, y_test = Montando_data_set_test(x12,x123,y12,y123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyKsDAPlbC_E"
      },
      "source": [
        "def get_classifier_model(input_shape):\n",
        "    \"\"\"\n",
        "        Model architecture\n",
        "    \"\"\"\n",
        "    \n",
        "    # Define the tensors for the two input images\n",
        "    left_input = Input(input_shape)\n",
        "    right_input = Input(input_shape)\n",
        "    \n",
        "    # Convolutional Neural Network\n",
        "    model = criando_rede(input_shape)\n",
        "\n",
        "\n",
        "    # Generate the encodings (feature vectors) for the two images\n",
        "    encoded_l = model(left_input)\n",
        "    encoded_r = model(right_input)\n",
        "    \n",
        "    # Add a customized layer to compute the absolute difference between the encodings\n",
        "    L1_layer = Lambda(lambda tensors:KER.backend.abs(tensors[0] - tensors[1]))\n",
        "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "    \n",
        "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
        "    prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(L1_distance)\n",
        "    \n",
        "    # Connect the inputs with the outputs\n",
        "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "    \n",
        "    # return the model\n",
        "    return siamese_net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE68FYjUO5fC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f1fe3206-797d-47cc-e9e1-a4b2b438e0e1"
      },
      "source": [
        "ip_shape = (9,1)\n",
        "model = get_classifier_model(ip_shape)\n",
        "epochs = 700\n",
        "optimizer = Adam(0.0005)\n",
        "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-dd4261fe764e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mip_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_classifier_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mip_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m700\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-155-a059f7b1514b>\u001b[0m in \u001b[0;36mget_classifier_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Convolutional Neural Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriando_rede\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-146-57320a5a811e>\u001b[0m in \u001b[0;36mcriando_rede\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0muse_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mbias_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    144\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m       printable_module_name='initializer')\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    390\u001b[0m       \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobject_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;31m# Classes passed by name are instantiated with no args, functions are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;31m# returned as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown initializer:glorot_uniform"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xtUYPbhPxId"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv8XY9cUSdGr"
      },
      "source": [
        "hist = model.fit(x_train, y_train, epochs=epochs,validation_data=(x_test,y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBaKArnPbTyY"
      },
      "source": [
        "def plot_learningCurve(history, epochs):\n",
        "\n",
        "  #Plot Training e validation accuracy values\n",
        "  epoch_range = range(1, epochs+1)\n",
        "  plt.plot(epoch_range, history.history['accuracy'])\n",
        "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  #Plot training e validation accuracy loss values\n",
        "  plt.plot(epoch_range, history.history['loss'])\n",
        "  plt.plot(epoch_range, history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DemvOa5UM-IW"
      },
      "source": [
        "plot_learningCurve(hist, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGJt42Y1vSIj"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS6EU2I9MN5K"
      },
      "source": [
        "Predict Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSSnqycfMLkq"
      },
      "source": [
        "def predict(model, x_aux):\n",
        "\n",
        "    prediction = model.predict(x_aux)\n",
        "    print(prediction)\n",
        "\n",
        "    prediction_index = np.argmin(prediction, axis=1)\n",
        "    print(\" Prediction index: {}\".format( prediction_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4jTWsBvM_1G"
      },
      "source": [
        "#48\t,23.5,\t70,\t2.707\t,0.467408666666667,\t8.8071,\t9.7024,\t7.99585\t,417.114 controle\n",
        "\n",
        "#58,\t29.1545189504373\t,139,\t16.582,\t5.68541506666667,\t22.8884\t,10.26266,\t13.97399\t,923.886 cancer\n",
        "\n",
        "#73,\t37.109375,\t134,\t5.636,\t1.86288586666667,\t41.4064\t,3.335665,\t6.89235,\t788.902 cancer\n",
        "\n",
        "#76,\t23.8\t,118,\t6.47,\t1.88320133333333,\t4.311,\t13.25132\t,5.1042,\t280.694 controle\n",
        "\n",
        "left =  [[48\t,23.5,\t70,\t2.707\t,0.467408666666667,\t8.8071,\t9.7024,\t7.99585\t,417.114]]\n",
        "right = [[73,\t37.109375,\t134,\t5.636,\t1.86288586666667,\t41.4064\t,3.335665,\t6.89235,\t788.902 ]]\n",
        "\n",
        "print(left)\n",
        "print(right)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "left = scaler.transform(left)\n",
        "right = scaler.transform(right)\n",
        "print(left)\n",
        "print(right)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "\n",
        "left = left.reshape(1,9,1)\n",
        "right = right.reshape(1,9,1)\n",
        "print(left)\n",
        "print(right)\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"------------------------------------\")\n",
        "\n",
        "test = [left, right]\n",
        "print(test)\n",
        "\n",
        "predict(model, test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}