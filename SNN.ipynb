{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dOY12W0rPlkkZ-LQHjhMT6J17JV-NSe2",
      "authorship_tag": "ABX9TyPTJeIEaXd8P/k2IXhRND89",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoGatti/BreastCancerSiameseNeuralNetwork/blob/main/SNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg3rOz7Qr_ip"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-rc0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSsHVLoYS-8k"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Input, Lambda, Reshape\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import ndarray\n",
        "import numpy.random as rng\n",
        "import random\n",
        "from keras.layers import add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo3Q8UTSTfAW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "outputId": "3e45e70f-d8d0-4543-f3c9-c9c2fb52a0cc"
      },
      "source": [
        "from keras import backend as K\n",
        "import keras as KER"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomRotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.layers.experimental.preprocessing'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5bf573a124e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mKER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     raise ImportError(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlWgLvFMTh50"
      },
      "source": [
        "from keras.layers import merge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk-JyrLETl9K"
      },
      "source": [
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUHpcxFSUQGL"
      },
      "source": [
        "def cosine(vector):\n",
        "  x, y = vector\n",
        "  dotx = K.sum(x*x, axis=1,keepdims=True)\n",
        "  doty = K.sum(y*y, axis=1,keepdims=True)\n",
        "  dotxy = K.sum(x*y, axis=1,keepdims=True)\n",
        "  cos = (dotxy/(K.sqrt(dotx) * K.sqrt(doty)))\n",
        "  return cos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H2WG6NVUbYb"
      },
      "source": [
        "def eucl_dist_output_shape(shapes):\n",
        "  shape1, shape2 = shapes\n",
        "  return shape1[0], 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KqVKYmnUfn6"
      },
      "source": [
        "def contrastive_loss(y_true,y_pred):\n",
        "  return K.mean(y_true*(2*K.exp(-(1/K.square(y_pred-1.2)))) + (1 - y_true)*(2*K.exp(-(1/K.square(y_pred+1.2)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5-Ph9VNUieb"
      },
      "source": [
        "def logistic_loss(y_true,y_pred):\n",
        "  return K.mean(K.log(1 * K.exp(-1*y_pred*y_true)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc2GMmsQUluL"
      },
      "source": [
        "def compute_accuracy(y_true,y_pred):\n",
        "  classified = K.round(y_pred)\n",
        "  return K.mean(K.equal(classified, y_true))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2oazzACUpER"
      },
      "source": [
        "def compute_final_accuracy(predictions, labels, print_prediction = False):\n",
        "  if print_prediction:\n",
        "    print(predictions)\n",
        "\n",
        "  classified = np.round(predictions.ravel())\n",
        "  return np.mean(classified == labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ3iQoeqUr83"
      },
      "source": [
        "def difference(vector):\n",
        "  x, y = vector\n",
        "  return x-y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkY4l42aUuG_"
      },
      "source": [
        "def cos_distance(vector):\n",
        "  return 1-cosine(vector)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8B4QW50UwqM"
      },
      "source": [
        "def distance(cos):\n",
        "  return 1 - K.abs(cos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fir_YS38VJxT"
      },
      "source": [
        "def create_base_network(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(keras.layers.Reshape(input_shape = (9, 1), target_shape=(9,1)))\n",
        "  model.add(Conv1D(filters=32, kernel_size=2, activation = 'relu', input_shape = (9,1)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "  model.add(Conv1D(filters=64, kernel_size=2, activation = 'relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation = 'relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1u7gj5mdOVA"
      },
      "source": [
        "def Transformacao(dataset):\n",
        "\n",
        "  novo_data = pd.DataFrame(data=dataset)\n",
        "  novo_data.drop('Classification',inplace=True,axis=1)  \n",
        "  data_x = novo_data \n",
        "  data_y = dataset.Classification\n",
        "  x_train = np.asarray(data_x)\n",
        "  y_train = np.asarray(data_y)\n",
        "  print(x_train)\n",
        "  test_x = []\n",
        "  test_y = []\n",
        "  for i in range(116):\n",
        "    if(i<5):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "    elif(i>112):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "\n",
        "\n",
        " # test_x = tf.cast(test_x, tf.float32)\n",
        "  test_x = np.asarray(test_x)\n",
        "  test_y = np.asarray(test_y)\n",
        "  print(test_x.shape)\n",
        "  print(test_y.shape)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  test_x = scaler.fit_transform(test_x)\n",
        "  x_train = scaler.fit_transform(x_train)\n",
        "  x_train = x_train.reshape(116,9,1)\n",
        "  test_x = test_x.reshape(8,9,1)\n",
        "\n",
        "  return test_x, test_x, test_y, test_y, scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhp1BppddU_N"
      },
      "source": [
        "def Montando_data_set(x_train,x_train1,y_train,y_train1):\n",
        "  target = []\n",
        "  trainx = []\n",
        "  trainx1 =[]\n",
        "  print(y_train)\n",
        "  print(y_train1)\n",
        "  print(len(x_train))\n",
        "  print(len(x_train1))\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      trainx.append(x_train[i])\n",
        "      trainx1.append(x_train1[j])\n",
        "      if(y_train[i] == y_train1[j]):\n",
        "        target.append(1)\n",
        "      else:\n",
        "        target.append(0)\n",
        "  trainx=np.asarray(trainx)\n",
        "  trainx = tf.cast(trainx, tf.float32)\n",
        "  trainx1=np.asarray(trainx1)\n",
        "  trainx1 = tf.cast(trainx1, tf.float32)\n",
        "  xtreino = [trainx,trainx1]\n",
        "  target = np.asarray(target)\n",
        "  target = tf.cast(target, tf.float32)\n",
        "\n",
        "  return xtreino,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPW0t5hxdZrc"
      },
      "source": [
        "def Transformacao_teste(dataset):\n",
        "\n",
        "  novo_data = pd.DataFrame(data=dataset)\n",
        "  novo_data.drop('Classification',inplace=True,axis=1)  \n",
        "  data_x = novo_data \n",
        "  data_y = dataset.Classification\n",
        "  x_train = np.asarray(data_x)\n",
        "  y_train = np.asarray(data_y)\n",
        "  print(x_train)\n",
        "  test_x = []\n",
        "  test_y = []\n",
        "  y = 0\n",
        "  for i in range(116):\n",
        "    if((i>7) & (i<15)):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "      y = y+1\n",
        "    elif((i>85) & (i<95) ):\n",
        "      test_x.append(x_train[i])\n",
        "      test_y.append(y_train[i])\n",
        "      y = y+1\n",
        "\n",
        "  print(y)\n",
        "  test_x = tf.cast(test_x, tf.float32)\n",
        "  #test_x = np.asarray(test_x)\n",
        "  test_y = np.asarray(test_y)\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  test_x = scaler.fit_transform(test_x)\n",
        "  print(test_x.shape)\n",
        "  test_x = test_x.reshape(16,9,1)\n",
        "\n",
        "  return test_x, test_x, test_y, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2iwxtAsdsXW"
      },
      "source": [
        "def Montando_data_set_test(x_train,x_train1,y_train,y_train1):\n",
        "  target = []\n",
        "  trainx = []\n",
        "  trainx1 =[]\n",
        "  print(y_train)\n",
        "  print(y_train1)\n",
        "  print(len(x_train))\n",
        "  print(len(x_train1))\n",
        "  for i in range(8):\n",
        "    for j in range(16):\n",
        "      trainx.append(x_train[i])\n",
        "      trainx1.append(x_train1[j])\n",
        "      if(y_train[i] == y_train1[j]):\n",
        "        target.append(1)\n",
        "      else:\n",
        "        target.append(0)\n",
        "  trainx=np.asarray(trainx)\n",
        "  trainx = tf.cast(trainx, tf.float32)\n",
        "  trainx1=np.asarray(trainx1)\n",
        "  trainx1 = tf.cast(trainx1, tf.float32)\n",
        "  xtreino = [trainx,trainx1]\n",
        "  target = np.asarray(target)\n",
        "  target = tf.cast(target, tf.float32)\n",
        "\n",
        "  return xtreino,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrxPVfam2JFe"
      },
      "source": [
        "initialize_bias = KER.initializers.RandomNormal(mean=0.0, stddev=0.1, seed=1221)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V9GTBBzWhGF"
      },
      "source": [
        "def execute(epochs=1000):\n",
        "  np.random.seed(100)\n",
        "  random.seed(100)\n",
        "  \n",
        "  #dataset\n",
        "\n",
        "  cancer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataR234.csv')\n",
        "  x, x1, y, y1, scaler = Transformacao(cancer)\n",
        "  x_train, y_train = Montando_data_set(x,x1,y,y1)\n",
        "\n",
        "  cancer = pd.read_csv('/content/drive/My Drive/Colab Notebooks/dataR234.csv')\n",
        "  x12, x123, y12, y123 = Transformacao_teste(cancer)\n",
        "  x_test, y_test = Montando_data_set_test(x,x123,y,y123)  \n",
        "\n",
        "\n",
        "  input = (9,1)\n",
        "  base_network_w = create_base_network(input)\n",
        "  left_input = Input(shape=(input))\n",
        "  right_input = Input(shape=(input)) \n",
        "\n",
        "  left = base_network_w(left_input)\n",
        "  right = base_network_w(right_input)\n",
        "\n",
        "  #both = merge([left, right], mode = cosine, output_shape = eucl_dist_output_shape)\n",
        "  both = tf.keras.layers.Dot(axes=1)([left, right])\n",
        "\n",
        "  prediction = Dense(1,activation='sigmoid',bias_initializer=initialize_bias)(both)\n",
        "\n",
        "  model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "\n",
        " # model = Model(inputs=[left_input,right_input],outputs=both)\n",
        "\n",
        "  loss = contrastive_loss\n",
        "  optimizer = Adam(0.0005)\n",
        "\n",
        "  #model.compile(loss=loss, optimizer = optimizer, metrics = [contrastive_loss, compute_accuracy])\n",
        "\n",
        "  model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  hist = model.fit(x_train, y_train, epochs=epochs,validation_data=(x_test,y_test), verbose=1)\n",
        "\n",
        "  return hist,model, x_test, y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay_qPjkAg4HB"
      },
      "source": [
        "hist, model,x_test, y_test = execute()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txSysnnzMr90"
      },
      "source": [
        "def plot_learningCurve(history, epochs):\n",
        "\n",
        "  #Plot Training e validation accuracy values\n",
        "  epoch_range = range(1, epochs+1)\n",
        "  plt.plot(epoch_range, history.history['accuracy'])\n",
        "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  #Plot training e validation accuracy loss values\n",
        "  plt.plot(epoch_range, history.history['loss'])\n",
        "  plt.plot(epoch_range, history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct0A8M-GMyt0"
      },
      "source": [
        "plot_learningCurve(hist, 2000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzC29FZMM1Nd"
      },
      "source": [
        "results = model.evaluate(x_test, y_test, batch_size=128)\n",
        "print('test loss, test acc:', results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}